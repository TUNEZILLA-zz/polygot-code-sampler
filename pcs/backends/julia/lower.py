"""
IR â†’ Julia lowering rules for loops and broadcast modes
"""

from .emitter import JL, jl_var, literal, gensym, julia_operator
from .types import julia_type, get_collection_type, get_reduction_type
from ...core import IRComp, IRGenerator, IRRange, IRReduce

def lower_program(ir: IRComp, mode: str = "loops", parallel: bool = False) -> str:
    """Lower IR to Julia code"""
    jl = JL(code=[])
    
    # Header
    jl.w("# Generated by PCS: Julia backend")
    jl.w("module PCS_Generated")
    jl.w("")
    jl.indent += 1
    
    # Add imports if needed
    if parallel:
        jl.w("using Base.Threads")
        jl.w("")
    
    # Generate main function
    _lower_entrypoint(jl, ir, mode=mode, parallel=parallel)
    
    jl.indent -= 1
    jl.w("")
    jl.w("end # module")
    
    return jl.render()

def _lower_entrypoint(jl: JL, ir: IRComp, mode: str, parallel: bool):
    """Lower the main entry point"""
    # Determine return type
    if ir.reduce:
        return_type = get_reduction_type(ir.reduce.kind)
    else:
        return_type = get_collection_type(ir.kind)
    
    jl.w(f"function main()::{return_type}")
    jl.indent += 1
    
    result_sym = _lower_comprehension(jl, ir, mode=mode, parallel=parallel)
    jl.w(f"return {result_sym}")
    
    jl.indent -= 1
    jl.w("end")

def _lower_comprehension(jl: JL, ir: IRComp, mode: str, parallel: bool) -> str:
    """Lower a comprehension to Julia code"""
    if len(ir.generators) == 1:
        gen = ir.generators[0]
        return _lower_single_generator(jl, ir, gen, mode, parallel)
    else:
        # Handle nested comprehensions
        return _lower_nested_comprehension(jl, ir, mode, parallel)

def _lower_single_generator(jl: JL, ir: IRComp, gen: IRGenerator, mode: str, parallel: bool) -> str:
    """Lower a single generator comprehension"""
    # Generate the source range
    source_sym = _lower_source(jl, gen.source)
    
    if ir.reduce:
        return _lower_reduction(jl, ir, gen, source_sym, mode, parallel)
    else:
        return _lower_collection(jl, ir, gen, source_sym, mode, parallel)

def _lower_source(jl: JL, source) -> str:
    """Lower source to Julia range"""
    if isinstance(source, IRRange):
        start, stop, step = source.start, source.stop, source.step
        if step == 1:
            return f"{start}:{stop-1}"  # Julia ranges are inclusive
        else:
            return f"{start}:{step}:{stop-1}"
    else:
        # Handle other source types
        return str(source)

def _lower_reduction(jl: JL, ir: IRComp, gen: IRGenerator, source_sym: str, mode: str, parallel: bool) -> str:
    """Lower reduction operations"""
    reduce_op = ir.reduce
    
    # Check if operation is safe to parallelize
    if parallel and not _is_associative_reduction(reduce_op.kind):
        # Fall back to sequential for non-associative operations
        jl.w("# Note: Sequential fallback - operation is not associative")
        parallel = False
    
    if parallel:
        return _lower_parallel_reduction(jl, ir, gen, source_sym, reduce_op)
    else:
        return _lower_sequential_reduction(jl, ir, gen, source_sym, reduce_op)

def _is_associative_reduction(kind: str) -> bool:
    """Check if reduction operation is associative and safe to parallelize"""
    return kind in ("sum", "prod", "max", "min")

def _lower_parallel_reduction(jl: JL, ir: IRComp, gen: IRGenerator, source_sym: str, reduce_op) -> str:
    """Lower parallel reduction using thread-local partials"""
    parts_sym = gensym("parts")
    acc_sym = gensym("acc")
    
    # Initialize thread-local partials
    if reduce_op.kind == "sum":
        jl.w(f"{parts_sym} = fill(0, nthreads())")
    elif reduce_op.kind == "prod":
        jl.w(f"{parts_sym} = fill(1, nthreads())")
    elif reduce_op.kind == "max":
        jl.w(f"{parts_sym} = fill(typemin(Int), nthreads())")
    elif reduce_op.kind == "min":
        jl.w(f"{parts_sym} = fill(typemax(Int), nthreads())")
    
    # Generate parallel loop
    loop_header = f"@threads for {gen.var} in {source_sym}"
    with jl.block(loop_header):
        # Apply filters
        if gen.filters:
            # Has filters - apply reduction only when filter passes
            for filter_expr in gen.filters:
                with jl.block(f"if {_lower_expression(filter_expr, gen.var)}"):
                    # Apply the reduction to thread-local partial
                    if ir.element:
                        mapped = _lower_expression(ir.element, gen.var)
                    else:
                        mapped = gen.var
                    
                    _apply_parallel_reduction(jl, parts_sym, mapped, reduce_op.kind)
        else:
            # No filters, apply reduction directly
            if ir.element:
                mapped = _lower_expression(ir.element, gen.var)
            else:
                mapped = gen.var
            
            _apply_parallel_reduction(jl, parts_sym, mapped, reduce_op.kind)
    
    # Combine thread-local partials
    jl.w(f"{acc_sym} = {_get_reduction_identity(reduce_op.kind)}")
    with jl.block(f"@inbounds for p in {parts_sym}"):
        _apply_reduction(jl, acc_sym, "p", reduce_op.kind)
    
    return acc_sym

def _lower_sequential_reduction(jl: JL, ir: IRComp, gen: IRGenerator, source_sym: str, reduce_op) -> str:
    """Lower sequential reduction"""
    acc_sym = gensym("acc")
    
    # Initialize accumulator
    jl.w(f"{acc_sym} = {_get_reduction_identity(reduce_op.kind)}")
    
    # Generate the loop
    with jl.block(f"for {gen.var} in {source_sym}"):
        # Apply filters
        if gen.filters:
            # Has filters - apply reduction only when filter passes
            for filter_expr in gen.filters:
                with jl.block(f"if {_lower_expression(filter_expr, gen.var)}"):
                    # Apply the reduction
                    if ir.element:
                        mapped = _lower_expression(ir.element, gen.var)
                    else:
                        mapped = gen.var
                    
                    _apply_reduction(jl, acc_sym, mapped, reduce_op.kind)
        else:
            # No filters, apply reduction directly
            if ir.element:
                mapped = _lower_expression(ir.element, gen.var)
            else:
                mapped = gen.var
            
            _apply_reduction(jl, acc_sym, mapped, reduce_op.kind)
    
    return acc_sym

def _get_reduction_identity(kind: str) -> str:
    """Get identity element for reduction operation"""
    if kind == "sum":
        return "0"
    elif kind == "prod":
        return "1"
    elif kind == "max":
        return "typemin(Int)"
    elif kind == "min":
        return "typemax(Int)"
    elif kind == "any":
        return "false"
    elif kind == "all":
        return "true"
    else:
        return "0"

def _lower_collection(jl: JL, ir: IRComp, gen: IRGenerator, source_sym: str, mode: str, parallel: bool) -> str:
    """Lower collection operations (list, set, dict)"""
    if ir.kind == "dict":
        return _lower_dict_comprehension(jl, ir, gen, source_sym, mode, parallel)
    else:
        return _lower_list_comprehension(jl, ir, gen, source_sym, mode, parallel)

def _lower_dict_comprehension(jl: JL, ir: IRComp, gen: IRGenerator, source_sym: str, mode: str, parallel: bool) -> str:
    """Lower dictionary comprehension"""
    if parallel:
        # Parallel dict writes are not safe - fall back to sequential
        jl.w("# Note: Sequential fallback - parallel dict writes are not thread-safe")
        parallel = False
    
    result_sym = gensym("dict")
    jl.w(f"{result_sym} = Dict{{Int, Int}}()")
    
    loop_header = f"for {gen.var} in {source_sym}"
    
    with jl.block(loop_header):
        # Apply filters
        if gen.filters:
            # Has filters - apply only when filter passes
            for filter_expr in gen.filters:
                with jl.block(f"if {_lower_expression(filter_expr, gen.var)}"):
                    key_expr = _lower_expression(ir.key_expr or gen.var, gen.var)
                    val_expr = _lower_expression(ir.val_expr or gen.var, gen.var)
                    jl.w(f"{result_sym}[{key_expr}] = {val_expr}")
        else:
            # No filters
            key_expr = _lower_expression(ir.key_expr or gen.var, gen.var)
            val_expr = _lower_expression(ir.val_expr or gen.var, gen.var)
            jl.w(f"{result_sym}[{key_expr}] = {val_expr}")
    
    return result_sym

def _lower_list_comprehension(jl: JL, ir: IRComp, gen: IRGenerator, source_sym: str, mode: str, parallel: bool) -> str:
    """Lower list/set comprehension"""
    result_sym = gensym("result")
    jl.w(f"{result_sym} = Int[]")
    
    loop_header = f"for {gen.var} in {source_sym}"
    if parallel:
        loop_header = f"@threads {loop_header}"
    
    with jl.block(loop_header):
        # Apply filters
        if gen.filters:
            # Has filters - apply only when filter passes
            for filter_expr in gen.filters:
                with jl.block(f"if {_lower_expression(filter_expr, gen.var)}"):
                    if ir.element:
                        mapped = _lower_expression(ir.element, gen.var)
                    else:
                        mapped = gen.var
                    jl.w(f"push!({result_sym}, {mapped})")
        else:
            # No filters
            if ir.element:
                mapped = _lower_expression(ir.element, gen.var)
            else:
                mapped = gen.var
            jl.w(f"push!({result_sym}, {mapped})")
    
    return result_sym

def _lower_nested_comprehension(jl: JL, ir: IRComp, mode: str, parallel: bool) -> str:
    """Lower nested comprehensions (simplified for now)"""
    result_sym = gensym("result")
    jl.w(f"{result_sym} = Int[]")
    jl.w("# Complex nested comprehension - simplified implementation")
    return result_sym

def _lower_expression(expr: str, var: str) -> str:
    """Lower Python expression to Julia expression"""
    # Simple expression translation
    # Replace variable references
    expr = expr.replace("x", var)
    
    # Convert Python operators to Julia operators
    expr = expr.replace("**", "^")
    expr = expr.replace("and", "&&")
    expr = expr.replace("or", "||")
    expr = expr.replace("not", "!")
    
    return expr

def _apply_reduction(jl: JL, acc_sym: str, mapped: str, reduce_kind: str):
    """Apply reduction operation"""
    if reduce_kind == "sum":
        jl.w(f"{acc_sym} += {mapped}")
    elif reduce_kind == "prod":
        jl.w(f"{acc_sym} *= {mapped}")
    elif reduce_kind == "max":
        jl.w(f"{acc_sym} = max({acc_sym}, {mapped})")
    elif reduce_kind == "min":
        jl.w(f"{acc_sym} = min({acc_sym}, {mapped})")
    elif reduce_kind == "any":
        jl.w(f"if {mapped}")
        jl.w(f"    {acc_sym} = true")
        jl.w("end")
    elif reduce_kind == "all":
        jl.w(f"if !({mapped})")
        jl.w(f"    {acc_sym} = false")
        jl.w("end")

def _apply_parallel_reduction(jl: JL, parts_sym: str, mapped: str, reduce_kind: str):
    """Apply reduction operation to thread-local partial"""
    if reduce_kind == "sum":
        jl.w(f"{parts_sym}[threadid()] += {mapped}")
    elif reduce_kind == "prod":
        jl.w(f"{parts_sym}[threadid()] *= {mapped}")
    elif reduce_kind == "max":
        jl.w(f"{parts_sym}[threadid()] = max({parts_sym}[threadid()], {mapped})")
    elif reduce_kind == "min":
        jl.w(f"{parts_sym}[threadid()] = min({parts_sym}[threadid()], {mapped})")
