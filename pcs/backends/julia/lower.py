"""
IR → Julia lowering rules for loops and broadcast modes
"""

from ...core import IRComp, IRGenerator, IRRange
from .emitter import JL, gensym, reset_gensym
from .strategy import choose_strategy, get_elem_type, get_op_kind, size_hint
from .types import get_collection_type, get_reduction_type


def lower_program(
    ir: IRComp,
    mode: str = "auto",
    parallel: bool = False,
    explain: bool = True,
    unsafe: bool = False,
) -> str:
    """Lower IR to Julia code"""
    # Reset gensym counter for deterministic output
    reset_gensym()

    jl = JL(code=[])

    # Generate stable module name to avoid collisions
    ir_text = str(ir)  # Simple string representation for hashing
    mod_hash = hash(ir_text) & 0xFFFF
    mod_name = f"PCS_Generated_{mod_hash:04x}"

    # Header
    jl.w("# Generated by PCS: Julia backend")
    jl.w(f"module {mod_name}")
    jl.w("")
    jl.indent += 1

    # Export alias for compatibility
    jl.w("const PCS_Generated = " + mod_name)
    jl.w("")

    # Add runtime include for parallel operations
    if parallel:
        jl.w('include("pcs_runtime.jl")')
        jl.w("using .PCS_Runtime")
        jl.w("")
    elif any(gen.filters for gen in ir.generators) or ir.reduce:
        # Add runtime for non-parallel operations that might benefit from helpers
        jl.w('include("pcs_runtime.jl")')
        jl.w("using .PCS_Runtime")
        jl.w("")

    # Generate main function
    _lower_entrypoint(
        jl, ir, mode=mode, parallel=parallel, explain=explain, unsafe=unsafe
    )

    jl.indent -= 1
    jl.w("")
    jl.w("end # module")

    return jl.render()


def _lower_entrypoint(
    jl: JL, ir: IRComp, mode: str, parallel: bool, explain: bool, unsafe: bool
):
    """Lower the main entry point"""
    # Determine return type
    if ir.reduce:
        return_type = get_reduction_type(ir.reduce.kind)
    else:
        return_type = get_collection_type(ir.kind)

    jl.w(f"function main()::{return_type}")
    jl.indent += 1

    # Use strategy selector to determine mode and parallel flavor
    elem_count_hint = size_hint(ir)  # Use cost model hook
    op_kind = get_op_kind(ir)
    elem_type = get_elem_type(ir)

    selected_mode, parallel_flavor, explanation = choose_strategy(
        ir,
        user_mode=mode,
        elem_count_hint=elem_count_hint,
        op_kind=op_kind,
        elem_type=elem_type,
        parallel_requested=parallel,
        explain=explain,
    )

    # Add explanation if provided
    if explanation:
        jl.w(explanation)

    # Add fail-fast diagnostics
    if explain:
        _add_diagnostics(jl, ir, selected_mode, parallel_flavor, unsafe)

    result_sym = _lower_comprehension(
        jl, ir, mode=selected_mode, parallel_flavor=parallel_flavor, unsafe=unsafe
    )
    jl.w(f"return {result_sym}")

    jl.indent -= 1
    jl.w("end")


def _add_diagnostics(jl: JL, ir: IRComp, mode: str, parallel_flavor: str, unsafe: bool):
    """Add fail-fast diagnostics with one-liner explanations"""

    # Non-deterministic gensym check
    jl.w("# NOTE: gensym reset at emit start for deterministic output")

    # Thread count check (if parallel)
    if parallel_flavor != "sequential":
        jl.w("# NOTE: actual thread count available via Threads.nthreads()")

    # Broadcast auto override check
    if mode == "loops" and any(gen.filters for gen in ir.generators):
        jl.w("# NOTE: loops selected to avoid allocations (filter present)")

    # Unsafe optimizations check
    if unsafe:
        jl.w("# NOTE: unsafe optimizations enabled (@inbounds/@simd)")


def _lower_comprehension(
    jl: JL, ir: IRComp, mode: str, parallel_flavor: str, unsafe: bool
) -> str:
    """Lower a comprehension to Julia code"""
    if len(ir.generators) == 1:
        gen = ir.generators[0]
        return _lower_single_generator(jl, ir, gen, mode, parallel_flavor, unsafe)
    else:
        # Handle nested comprehensions
        return _lower_nested_comprehension(jl, ir, mode, parallel_flavor, unsafe)


def _lower_single_generator(
    jl: JL, ir: IRComp, gen: IRGenerator, mode: str, parallel_flavor: str, unsafe: bool
) -> str:
    """Lower a single generator comprehension"""
    # Generate the source range
    source_sym = _lower_source(jl, gen.source)

    # Choose between loop and broadcast modes
    if mode == "broadcast" and _should_use_broadcast(ir, gen):
        return _lower_broadcast(jl, ir, gen, source_sym, parallel_flavor, unsafe)
    else:
        # Handle different operations in loop mode
        if ir.reduce:
            return _lower_reduction(
                jl, ir, gen, source_sym, mode, parallel_flavor, unsafe
            )
        else:
            return _lower_collection(
                jl, ir, gen, source_sym, mode, parallel_flavor, unsafe
            )


def _should_use_broadcast(ir: IRComp, gen: IRGenerator) -> bool:
    """Determine if broadcast mode is appropriate for this IR"""
    # Use broadcast for simple element-wise operations
    if ir.element and not any(
        char in ir.element for char in ["if", "else", "and", "or"]
    ):
        return True
    # Use broadcast for simple reductions without complex filters
    if ir.reduce and not gen.filters:
        return True
    return False


def _lower_broadcast(
    jl: JL,
    ir: IRComp,
    gen: IRGenerator,
    source_sym: str,
    parallel_flavor: str,
    unsafe: bool,
) -> str:
    """Lower using broadcast/vectorized operations"""
    if ir.reduce:
        return _lower_broadcast_reduction(
            jl, ir, gen, source_sym, parallel_flavor, unsafe
        )
    else:
        return _lower_broadcast_collection(
            jl, ir, gen, source_sym, parallel_flavor, unsafe
        )


def _lower_broadcast_reduction(
    jl: JL,
    ir: IRComp,
    gen: IRGenerator,
    source_sym: str,
    parallel_flavor: str,
    unsafe: bool,
) -> str:
    """Lower reduction using broadcast operations"""

    if gen.filters:
        # Use ifelse for dot-fusion: sum(ifelse.(condition, values, 0))
        filter_expr = _lower_expression(gen.filters[0], gen.var)
        if ir.element:
            mapped_expr = _lower_expression(ir.element, gen.var)
        else:
            mapped_expr = gen.var

        # Create broadcast expression
        broadcast_expr = f"ifelse.({filter_expr}, {mapped_expr}, 0)"
        result_sym = gensym("result")
        jl.w(f"{result_sym} = sum({broadcast_expr})")
        return result_sym
    else:
        # Simple broadcast reduction
        if ir.element:
            mapped_expr = _lower_expression(ir.element, gen.var)
        else:
            mapped_expr = gen.var

        result_sym = gensym("result")
        jl.w(f"{result_sym} = sum({mapped_expr})")
        return result_sym


def _lower_broadcast_collection(
    jl: JL,
    ir: IRComp,
    gen: IRGenerator,
    source_sym: str,
    parallel_flavor: str,
    unsafe: bool,
) -> str:
    """Lower collection using broadcast operations"""
    if gen.filters:
        # Use logical indexing: xs[condition]
        filter_expr = _lower_expression(gen.filters[0], gen.var)
        if ir.element:
            mapped_expr = _lower_expression(ir.element, gen.var)
        else:
            mapped_expr = gen.var

        result_sym = gensym("result")
        jl.w(f"{result_sym} = {mapped_expr}[{filter_expr}]")
        return result_sym
    else:
        # Simple broadcast mapping
        if ir.element:
            mapped_expr = _lower_expression(ir.element, gen.var)
        else:
            mapped_expr = gen.var

        result_sym = gensym("result")
        jl.w(f"{result_sym} = {mapped_expr}")
        return result_sym


def _lower_source(jl: JL, source) -> str:
    """Lower source to Julia range"""
    if isinstance(source, IRRange):
        start, stop, step = source.start, source.stop, source.step
        if step == 1:
            return f"{start}:{stop-1}"  # Julia ranges are inclusive
        else:
            return f"{start}:{step}:{stop-1}"
    else:
        # Handle other source types
        return str(source)


def _lower_reduction(
    jl: JL,
    ir: IRComp,
    gen: IRGenerator,
    source_sym: str,
    mode: str,
    parallel_flavor: str,
    unsafe: bool,
) -> str:
    """Lower reduction operations"""
    reduce_op = ir.reduce

    if parallel_flavor == "threadlocals":
        return _lower_parallel_reduction(jl, ir, gen, source_sym, reduce_op, unsafe)
    else:
        return _lower_sequential_reduction(jl, ir, gen, source_sym, reduce_op, unsafe)


# Associativity whitelist for safe parallelization
ASSOCIATIVE_OPS = {
    "sum": ("Int", "Float64"),  # sum reduction
    "prod": ("Int", "Float64"),  # product reduction
    "max": ("Int", "Float64"),
    "min": ("Int", "Float64"),
    "+": ("Int", "Float64"),  # addition operator
    "*": ("Int", "Float64"),  # multiplication operator
    "|": ("Int",),  # bitwise OR
    "&": ("Int",),  # bitwise AND
    "^": ("Int",),  # bitwise XOR
}


def _is_associative_reduction(kind: str) -> bool:
    """Check if reduction operation is associative and safe to parallelize"""
    return kind in ASSOCIATIVE_OPS


def _get_associativity_note(kind: str) -> str:
    """Get explanatory note for non-associative operations"""
    if kind in ("any", "all"):
        return f"# NOTE: sequential fallback — non-associative operation '{kind}'"
    else:
        return f"# NOTE: sequential fallback — operation '{kind}' not in associativity whitelist"


def _lower_parallel_reduction(
    jl: JL, ir: IRComp, gen: IRGenerator, source_sym: str, reduce_op, unsafe: bool
) -> str:
    """Lower parallel reduction using thread-local partials"""
    parts_sym = gensym("parts")
    acc_sym = gensym("acc")

    # Initialize thread-local partials
    if reduce_op.kind == "sum":
        jl.w(f"{parts_sym} = fill(0, nthreads())")
    elif reduce_op.kind == "prod":
        jl.w(f"{parts_sym} = fill(1, nthreads())")
    elif reduce_op.kind == "max":
        jl.w(f"{parts_sym} = fill(typemin(Int), nthreads())")
    elif reduce_op.kind == "min":
        jl.w(f"{parts_sym} = fill(typemax(Int), nthreads())")

    # Generate parallel loop
    loop_header = f"@threads for {gen.var} in {source_sym}"
    with jl.block(loop_header):
        # Apply filters
        if gen.filters:
            # Has filters - apply reduction only when filter passes
            for filter_expr in gen.filters:
                with jl.block(f"if {_lower_expression(filter_expr, gen.var)}"):
                    # Apply the reduction to thread-local partial
                    if ir.element:
                        mapped = _lower_expression(ir.element, gen.var)
                    else:
                        mapped = gen.var

                    _apply_parallel_reduction(jl, parts_sym, mapped, reduce_op.kind)
        else:
            # No filters, apply reduction directly
            if ir.element:
                mapped = _lower_expression(ir.element, gen.var)
            else:
                mapped = gen.var

            _apply_parallel_reduction(jl, parts_sym, mapped, reduce_op.kind)

    # Combine thread-local partials
    jl.w(f"{acc_sym} = {_get_reduction_identity(reduce_op.kind)}")
    bounds_check = "@inbounds" if unsafe else ""
    with jl.block(f"{bounds_check} for p in {parts_sym}"):
        _apply_reduction(jl, acc_sym, "p", reduce_op.kind)

    return acc_sym


def _lower_sequential_reduction(
    jl: JL, ir: IRComp, gen: IRGenerator, source_sym: str, reduce_op, unsafe: bool
) -> str:
    """Lower sequential reduction"""
    acc_sym = gensym("acc")

    # Initialize accumulator
    jl.w(f"{acc_sym} = {_get_reduction_identity(reduce_op.kind)}")

    # Generate the loop
    with jl.block(f"for {gen.var} in {source_sym}"):
        # Apply filters
        if gen.filters:
            # Has filters - apply reduction only when filter passes
            for filter_expr in gen.filters:
                with jl.block(f"if {_lower_expression(filter_expr, gen.var)}"):
                    # Apply the reduction
                    if ir.element:
                        mapped = _lower_expression(ir.element, gen.var)
                    else:
                        mapped = gen.var

                    _apply_reduction(jl, acc_sym, mapped, reduce_op.kind)
        else:
            # No filters, apply reduction directly
            if ir.element:
                mapped = _lower_expression(ir.element, gen.var)
            else:
                mapped = gen.var

            _apply_reduction(jl, acc_sym, mapped, reduce_op.kind)

    return acc_sym


def _get_reduction_identity(kind: str) -> str:
    """Get identity element for reduction operation"""
    if kind == "sum":
        return "0"
    elif kind == "prod":
        return "1"
    elif kind == "max":
        return "typemin(Int)"
    elif kind == "min":
        return "typemax(Int)"
    elif kind == "any":
        return "false"
    elif kind == "all":
        return "true"
    else:
        return "0"


def _lower_collection(
    jl: JL,
    ir: IRComp,
    gen: IRGenerator,
    source_sym: str,
    mode: str,
    parallel_flavor: str,
    unsafe: bool,
) -> str:
    """Lower collection operations (list, set, dict, group_by)"""
    if ir.kind == "dict":
        return _lower_dict_comprehension(
            jl, ir, gen, source_sym, mode, parallel_flavor, unsafe
        )
    elif ir.kind == "group_by":
        return _lower_group_by(jl, ir, gen, source_sym, mode, parallel_flavor, unsafe)
    else:
        return _lower_list_comprehension(
            jl, ir, gen, source_sym, mode, parallel_flavor, unsafe
        )


def _lower_dict_comprehension(
    jl: JL,
    ir: IRComp,
    gen: IRGenerator,
    source_sym: str,
    mode: str,
    parallel_flavor: str,
    unsafe: bool,
) -> str:
    """Lower dictionary comprehension"""
    if parallel_flavor == "sharded":
        return _lower_parallel_dict_comprehension(jl, ir, gen, source_sym, unsafe)
    else:
        return _lower_sequential_dict_comprehension(jl, ir, gen, source_sym, unsafe)


def _lower_parallel_dict_comprehension(
    jl: JL, ir: IRComp, gen: IRGenerator, source_sym: str, unsafe: bool
) -> str:
    """Lower parallel dictionary comprehension using runtime helpers"""
    result_sym = gensym("result")

    # Use runtime helper for parallel dict comprehension
    key_expr = _lower_expression(ir.key_expr or gen.var, gen.var)
    val_expr = _lower_expression(ir.val_expr or gen.var, gen.var)

    # Generate key and value functions with proper variable substitution
    key_func = f"i -> {key_expr.replace(gen.var, 'i')}"
    val_func = f"i -> {val_expr.replace(gen.var, 'i')}"

    jl.w(
        f"{result_sym} = dict_comp_parallel({source_sym}, {key_func}, {val_func}; KT=Int, VT=Int, combine=(o,n)->n)"
    )

    return result_sym


def _lower_sequential_dict_comprehension(
    jl: JL, ir: IRComp, gen: IRGenerator, source_sym: str, unsafe: bool
) -> str:
    """Lower sequential dictionary comprehension"""
    result_sym = gensym("dict")
    jl.w(f"{result_sym} = Dict{{Int, Int}}()")

    with jl.block(f"for {gen.var} in {source_sym}"):
        # Apply filters
        if gen.filters:
            # Has filters - apply only when filter passes
            for filter_expr in gen.filters:
                with jl.block(f"if {_lower_expression(filter_expr, gen.var)}"):
                    key_expr = _lower_expression(ir.key_expr or gen.var, gen.var)
                    val_expr = _lower_expression(ir.val_expr or gen.var, gen.var)
                    jl.w(f"{result_sym}[{key_expr}] = {val_expr}")
        else:
            # No filters
            key_expr = _lower_expression(ir.key_expr or gen.var, gen.var)
            val_expr = _lower_expression(ir.val_expr or gen.var, gen.var)
            jl.w(f"{result_sym}[{key_expr}] = {val_expr}")

    return result_sym


def _lower_group_by(
    jl: JL,
    ir: IRComp,
    gen: IRGenerator,
    source_sym: str,
    mode: str,
    parallel_flavor: str,
    unsafe: bool,
) -> str:
    """Lower group-by operations"""
    if parallel_flavor == "sharded":
        return _lower_parallel_group_by(jl, ir, gen, source_sym, unsafe)
    else:
        return _lower_sequential_group_by(jl, ir, gen, source_sym, unsafe)


def _lower_parallel_group_by(
    jl: JL, ir: IRComp, gen: IRGenerator, source_sym: str, unsafe: bool
) -> str:
    """Lower parallel group-by using shard pattern"""
    result_sym = gensym("result")
    shards_sym = gensym("shards")

    # Create shards for each thread
    jl.w(f"{shards_sym} = [Dict{{Int, Vector{{Int}}}}() for _ in 1:nthreads()]")

    # Parallel loop with thread-local writes
    with jl.block(f"@threads for {gen.var} in {source_sym}"):
        # Apply filters
        if gen.filters:
            # Has filters - apply only when filter passes
            for filter_expr in gen.filters:
                with jl.block(f"if {_lower_expression(filter_expr, gen.var)}"):
                    key_expr = _lower_expression(ir.key_expr or gen.var, gen.var)
                    val_expr = _lower_expression(ir.val_expr or gen.var, gen.var)
                    jl.w(f"sh = {shards_sym}[threadid()]")
                    jl.w(f"v = get!(sh, {key_expr}, Vector{{Int}}())")
                    jl.w(f"push!(v, {val_expr})")
        else:
            # No filters
            key_expr = _lower_expression(ir.key_expr or gen.var, gen.var)
            val_expr = _lower_expression(ir.val_expr or gen.var, gen.var)
            jl.w(f"sh = {shards_sym}[threadid()]")
            jl.w(f"v = get!(sh, {key_expr}, Vector{{Int}}())")
            jl.w(f"push!(v, {val_expr})")

    # Merge shards serially
    jl.w(f"{result_sym} = Dict{{Int, Vector{{Int}}}}()")
    bounds_check = "@inbounds" if unsafe else ""
    with jl.block(f"{bounds_check} for sh in {shards_sym}"):
        with jl.block("for (k, v) in sh"):
            jl.w(f"dst = get!({result_sym}, k, Vector{{Int}}())")
            jl.w("append!(dst, v)")

    return result_sym


def _lower_sequential_group_by(
    jl: JL, ir: IRComp, gen: IRGenerator, source_sym: str, unsafe: bool
) -> str:
    """Lower sequential group-by"""
    result_sym = gensym("result")
    jl.w(f"{result_sym} = Dict{{Int, Vector{{Int}}}}()")

    with jl.block(f"for {gen.var} in {source_sym}"):
        # Apply filters
        if gen.filters:
            # Has filters - apply only when filter passes
            for filter_expr in gen.filters:
                with jl.block(f"if {_lower_expression(filter_expr, gen.var)}"):
                    key_expr = _lower_expression(ir.key_expr or gen.var, gen.var)
                    val_expr = _lower_expression(ir.val_expr or gen.var, gen.var)
                    jl.w(f"v = get!({result_sym}, {key_expr}, Vector{{Int}}())")
                    jl.w(f"push!(v, {val_expr})")
        else:
            # No filters
            key_expr = _lower_expression(ir.key_expr or gen.var, gen.var)
            val_expr = _lower_expression(ir.val_expr or gen.var, gen.var)
            jl.w(f"v = get!({result_sym}, {key_expr}, Vector{{Int}}())")
            jl.w(f"push!(v, {val_expr})")

    return result_sym


def _lower_list_comprehension(
    jl: JL, ir: IRComp, gen: IRGenerator, source_sym: str, mode: str, parallel: bool
) -> str:
    """Lower list/set comprehension"""
    result_sym = gensym("result")
    jl.w(f"{result_sym} = Int[]")

    loop_header = f"for {gen.var} in {source_sym}"
    if parallel:
        loop_header = f"@threads {loop_header}"

    with jl.block(loop_header):
        # Apply filters
        if gen.filters:
            # Has filters - apply only when filter passes
            for filter_expr in gen.filters:
                with jl.block(f"if {_lower_expression(filter_expr, gen.var)}"):
                    if ir.element:
                        mapped = _lower_expression(ir.element, gen.var)
                    else:
                        mapped = gen.var
                    jl.w(f"push!({result_sym}, {mapped})")
        else:
            # No filters
            if ir.element:
                mapped = _lower_expression(ir.element, gen.var)
            else:
                mapped = gen.var
            jl.w(f"push!({result_sym}, {mapped})")

    return result_sym


def _lower_nested_comprehension(jl: JL, ir: IRComp, mode: str, parallel: bool) -> str:
    """Lower nested comprehensions (simplified for now)"""
    result_sym = gensym("result")
    jl.w(f"{result_sym} = Int[]")
    jl.w("# Complex nested comprehension - simplified implementation")
    return result_sym


def _lower_expression(expr: str, var: str) -> str:
    """Lower Python expression to Julia expression"""
    # Simple expression translation
    # Replace variable references
    expr = expr.replace("x", var)

    # Convert Python operators to Julia operators
    expr = expr.replace("**", "^")
    expr = expr.replace("and", "&&")
    expr = expr.replace("or", "||")
    expr = expr.replace("not", "!")

    return expr


def _apply_reduction(jl: JL, acc_sym: str, mapped: str, reduce_kind: str):
    """Apply reduction operation"""
    if reduce_kind == "sum":
        jl.w(f"{acc_sym} += {mapped}")
    elif reduce_kind == "prod":
        jl.w(f"{acc_sym} *= {mapped}")
    elif reduce_kind == "max":
        jl.w(f"{acc_sym} = max({acc_sym}, {mapped})")
    elif reduce_kind == "min":
        jl.w(f"{acc_sym} = min({acc_sym}, {mapped})")
    elif reduce_kind == "any":
        jl.w(f"if {mapped}")
        jl.w(f"    {acc_sym} = true")
        jl.w("end")
    elif reduce_kind == "all":
        jl.w(f"if !({mapped})")
        jl.w(f"    {acc_sym} = false")
        jl.w("end")


def _apply_parallel_reduction(jl: JL, parts_sym: str, mapped: str, reduce_kind: str):
    """Apply reduction operation to thread-local partial"""
    if reduce_kind == "sum":
        jl.w(f"{parts_sym}[threadid()] += {mapped}")
    elif reduce_kind == "prod":
        jl.w(f"{parts_sym}[threadid()] *= {mapped}")
    elif reduce_kind == "max":
        jl.w(f"{parts_sym}[threadid()] = max({parts_sym}[threadid()], {mapped})")
    elif reduce_kind == "min":
        jl.w(f"{parts_sym}[threadid()] = min({parts_sym}[threadid()], {mapped})")
